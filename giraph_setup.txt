
	
	
======================== HANDY COMMANDS =======================

Start all: start-dfs.sh && start-yarn.sh
Stop all: stop-yarn.sh && stop-dfs.sh

	
	
==========================  HDFS + YARN SETUP  =========================================================================================

1. Install proper java version (latest is not supported by Hadoop yet). 
	Use Java 8 as stated on hadoop website or here: https://stackoverflow.com/questions/52155078/how-to-fix-hadoop-warning-an-illegal-reflective-access-operation-has-occurred-e
	Some of the machines have Java 10 installed. The way to configure is install Java 8 and change default version to 8.
	Java versions can co-exist, so install what is needed and use it for hadoop
	https://stackoverflow.com/questions/12836666/how-to-remove-open-jdk-completely-in-ubuntu
	sudo add-apt-repository ppa:openjdk-r/ppa
	sudo apt-get update
	sudo apt-get install openjdk-8-jdk
	To see available versions: 	update-alternatives --display java
	
2. Download a stable hadoop version. 

3. Create a common user for hadoop on all machines, and a common group to set as a supergroup. 223B PROJECT: Skip this step.
	Username: hadoop
	Password: <Ask>

	useradd hadoop
	addgroup hadoopgroup
	sudo usermod -a -G hadoopgroup ayelam
	
	Set dfs.permissions.superusergroup to this group in hdfs-site.xml
	
	<property>
		<name>dfs.permissions.superusergroup</name>
		<value>hadoopgroup</value>
	</property>
	
	Or set HDFS permissions checks to false as this is dev environment
	<property>
		<name>dfs.permissions.enabled</name>
		<value>false</value>
	</property>

3. Figure out the network names to use for all the nodes. 
	In our case, we have to let the traffic go through a specific network interface. 
	Start with b09-40(10.0.0.1) and b09-38 (10.0.1.1)
	Generate ssh key: 
		ssh-keygen -b 4096
	Copy it to all the machines:
		ssh-copy-id -i $HOME/.ssh/id_rsa.pub hadoop@10.0.0.1
		ssh-copy-id -i $HOME/.ssh/id_rsa.pub hadoop@10.0.1.1
	223B PROJECT: Generate the key pair on the master server, then copy the public key to all the servers using scp. 
	Then add the public key to .ssh/authorized_keys on all the subordinate servers. Also put the public key in authorized_keys in 		the master node. 
	
4. Copy unzipped hadoop to home folder of hadoop user on all machines (do it from hadoop user context so it retains permissions)

( Errors ignored:
cp: cannot open 'hadoop/share/hadoop/httpfs/tomcat/conf/catalina.properties' for reading: Permission denied
cp: cannot open 'hadoop/share/hadoop/httpfs/tomcat/conf/catalina.policy' for reading: Permission denied
cp: cannot open 'hadoop/share/hadoop/httpfs/tomcat/conf/tomcat-users.xml' for reading: Permission denied
cp: cannot open 'hadoop/share/hadoop/httpfs/tomcat/conf/context.xml' for reading: Permission denied
cp: cannot open 'hadoop/share/hadoop/httpfs/tomcat/conf/web.xml' for reading: Permission denied
cp: cannot open 'hadoop/share/hadoop/kms/tomcat/conf/context.xml' for reading: Permission denied
cp: cannot open 'hadoop/share/hadoop/kms/tomcat/conf/web.xml' for reading: Permission denied
cp: cannot open 'hadoop/share/hadoop/kms/tomcat/conf/catalina.properties' for reading: Permission denied
cp: cannot open 'hadoop/share/hadoop/kms/tomcat/conf/catalina.policy' for reading: Permission denied
cp: cannot open 'hadoop/share/hadoop/kms/tomcat/conf/tomcat-users.xml' for reading: Permission denied
)

	And add the folder to path by adding below line to .profile file (/usr/local/home/hadoop/.profile)
	PATH=/usr/local/home/hadoop/hadoop/bin:/usr/local/home/hadoop/hadoop/sbin:$PATH
		223B PROJECT: .profile is in the folder setup_resources
	
5. Set JAVA_HOME (on all nodes). Use Java 8 installed in step 1. 223B PROJECT: Skip this step if you copied the previous hadoop installation, it's already complete.
	Edit ~/hadoop/etc/hadoop/hadoop-env.sh and replace this line:
	vim ~/hadoop/etc/hadoop/hadoop-env.sh
	export JAVA_HOME=${JAVA_HOME} with
	export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre
	
6. Set name node location on each node by updating ~/hadoop/etc/hadoop/core-site.xml. 223B PROJECT: All of the subordinate nodes need to have giraph1 as the hostname, but the master node needs to have localhost.
	<?xml version="1.0" encoding="UTF-8"?>
	<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
        <property>
            <name>fs.default.name</name>
            <value>hdfs://10.0.0.1:9000</value>
        </property>
    </configuration>
	
7. Set path for HDFS, editing hdfs-site.xml
	<configuration>
		<property>
				<name>dfs.namenode.name.dir</name>
				<value>/usr/local/home/hadoop/data/nameNode</value> 
		</property>

		<property>
				<name>dfs.datanode.data.dir</name>
				<value>/usr/local/home/hadoop/data/dataNode</value>
		</property>

		<property>
				<name>dfs.replication</name>
				<value>1</value>
		</property>
	</configuration>
	
8. Set YARN as Job scheduler. 223B PROJECT: Already done.
	https://www.linode.com/docs/databases/hadoop/how-to-install-and-set-up-hadoop-cluster/#set-yarn-as-job-scheduler
	cd hadoop/etc/hadoop/
	mv mapred-site.xml.template mapred-site.xml
	vim mapred-site.xml and place the below text:
	<configuration>
		<property>
            <name>mapreduce.framework.name</name>
            <value>yarn</value>
		</property>
	</configuration>
	
9. Configure YARN
	vim yarn-site-xml
	<configuration>
    <property>
            <name>yarn.acl.enable</name>
            <value>0</value>
    </property>

    <property>
            <name>yarn.resourcemanager.hostname</name>
            <value>127.0.0.1</value>
    </property>

    <property>
            <name>yarn.nodemanager.aux-services</name>
            <value>mapreduce_shuffle</value>
    </property>
	</configuration>
	
	
10. Configure slaves files and add names of all the slaves, in ~/hadoop/etc/hadoop/slaves
	b09-44.sysnet.ucsd.edu
	b09-42.sysnet.ucsd.edu
	b09-40.sysnet.ucsd.edu
	b09-38.sysnet.ucsd.edu
	b09-36.sysnet.ucsd.edu
	b09-34.sysnet.ucsd.edu
	b09-32.sysnet.ucsd.edu
	b09-30.sysnet.ucsd.edu
	
11. Set memory allocation for containers. Check this config for current cluster!!

	Edit /home/hadoop/hadoop/etc/hadoop/yarn-site.xml and add the following lines:
	<property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>61440</value>
	</property>

	<property>
			<name>yarn.scheduler.maximum-allocation-mb</name>
			<value>61440</value>
	</property>

	<property>
			<name>yarn.scheduler.minimum-allocation-mb</name>
			<value>1024</value>
	</property>

	<property>
			<name>yarn.nodemanager.vmem-check-enabled</name>
			<value>false</value>
	</property>
	
	Edit /home/hadoop/hadoop/etc/hadoop/mapred-site.xml and add the following lines: (DON'T WORRY ABOUT THIS FOR SPARK + YARN)
	<property>
        <name>yarn.app.mapreduce.am.resource.mb</name>
        <value>10240</value>
	</property>

	<property>
			<name>mapreduce.map.memory.mb</name>
			<value>10240</value>
	</property>

	<property>
			<name>mapreduce.reduce.memory.mb</name>
			<value>10240</value>
	</property>
	
12. Copy config files to all the slave nodes
	scp ~/hadoop/etc/hadoop/* (slave_name):/usr/local/home/hadoop/hadoop/etc/hadoop/
	
	
13. Format HDFS and it is now ready to use.
	hdfs namenode -format
	
	
14. Start dfs
	start-dfs.sh
	Accept secondary name node on [0.0.0.0]. Then you can browse hdfs on http://b09-40.sysnet.ucsd.edu:50070
	Datanode bug: Set this setting in hdfs-default.xml to false to turn off data node name resolution. dfs.namenode.datanode.registration.ip-hostname-check
		<property>
			<name>dfs.namenode.datanode.registration.ip-hostname-check</name>
			<value>false</value>
		</property>
	
	
15. To stop dfs: stop-dfs.sh
16. Check: hdfs dfsadmin -report

17. Run YARN: 
	start-yarn.sh
	stop-yarn.sh
	yarn node -list
	yarn application -list
	Web UI at http://b09-40.sysnet.ucsd.edu:8088

18. Adding more nodes. To summarize for b09-36:
	With ayelam on new node:
		sudo adduser hadoop
		sudo addgroup hadoopgroup
		update-alternatives --display java
		sudo apt-get install openjdk-8-jdk
	With hadoop user on b09-30:
		Add new node to ~/hadoop/etc/hadoop/slaves file
		ssh-copy-id -i $HOME/.ssh/id_rsa.pub hadoop@b09-44
		scp .profile b09-44:~/
		scp -r ~/hadoop b09-44:~/
		
	
========================================= INTEGRATING GIRAPH =================================================================

http://giraph.apache.org/quick_start.html
1. Make sure you can run general map-reduce jobs, as that is what Giraph is built on.

2. Clone Giraph repo from GitHub and compile it for YARN and target Hadoop version
	sudo git clone https://github.com/apache/giraph.git
  git clone https://github.com/apache/giraph.git
  cd giraph/
  export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64
  (Due to some java version mismatch while running giraph on hadoop, we have to build giraph using Java 11 version, not the default 8 version.
  To update default java, use this command: sudo update-alternatives --config java)

  For PURE YARN (we don't use pure yarn, see below): 
  	mvn -Phadoop_yarn -DskipTests -Dhadoop.version=2.8.5 clean install -Dcheckstyle.skip
  	(1. Needed to do a little hack of removing an option from <munge.symbols> in pom.xml for YARN, based on the below link to get compile to work: 
  		http://mail-archives.apache.org/mod_mbox/giraph-user/201501.mbox/%3C54B17196.4040107@hiro-tan.org%3E
	2. Maven version was really important. Use only 3.5.2
		apt-get install maven=3.5.2)
  For MapReduce on YARN (we use this now): 
  	mvn -Phadoop_2 clean install -DskipTests -Dcheckstyle.skip

3. At this point, we'll have a Giraph jar file custom built for Hadoop version, and can be executed using "hadoop jar" over MR.

4. Run below command to see options:
	hadoop jar /usr/local/home/hadoop/giraph/giraph-examples/target/giraph-examples-1.3.0-SNAPSHOT-for-hadoop-2.8.5-jar-with-dependencies.jar org.apache.giraph.GiraphRunner -h

5. The example in the above link (SimpleShortestPathsComputation) failed at first. The jar is not being picked up, so had to copy it to yarn libs folder (ON ALL NODES!)
	https://stackoverflow.com/questions/29001491/could-not-find-or-load-main-class-org-apache-giraph-yarn-giraphapplicationmaster

6. Test command
	

Helpful links:
https://blog.cloudera.com/blog/2014/02/how-to-write-and-run-giraph-jobs-on-hadoop/
https://yogin16.github.io/2018/04/09/giraph-hadoop-setup/



======================================== LOADING VARIOUS GRAPH DATASETS IN GIRAPH ==============================================

Graph datasets from various sources need some pre-processing to convert them to acceptable formats for Giraph. This includes using some custom tools (that come along with datasets)
to convert graphs to an intermediate format, and writing simple input graph parsers in Giraph for consuming the intermediate format. 

========= Facebook's Darwini Datasets "https://fb-public.app.box.com/s/f13axyrxrt00zmc4sn2vz8mid6ykm109"
	1. Big darwini datasets have graphs broken down into multiple files in gzip format. We need to 'gunzip' each of these into normal text files. 
		cd darwini-10b-edges/
		gunzip part-m-*
	2. Once unzipped, we upload the directory to hdfs 
		hdfs dfs  -D dfs.replication=2  -put /usr/local/home/ayelam/darwini-5b-edges/  /user/ayelam/graph_inputs/
		hdfs dfs -setrep 1 /user/ayelam/graph_inputs/darwini-5b-edges				-- To get uniform data placement with 1 replication
		hdfs dfs -du -h /user/ayelam/graph_inputs/darwini-5b-edges					-- To see size	
		hdfs cacheadmin -addDirective -path "/user/ayelam/graph_inputs/darwini-5b-edges" -pool cache-pool		-- Cache if necessary
	3. Use the directory as input to Giraph, Giraph will parse through all the files.
	4. On Giraph side, I wrote a parser that can parse this graph: org/apache/giraph/io/formats/LongDoubleFloatTextInputFormat.java
		giraph <...> -vif org.apache.giraph.io.formats.LongDoubleFloatTextInputFormat -vip /user/ayelam/graph_inputs/darwini-5b-edges <...>


========= Lab for Web Algorithmics' Datasets "http://law.di.unimi.it/datasets.php"
	1. Graphs are compressed with WebGraph tool (http://webgraph.di.unimi.it/) in 'it.unimi.dsi.webgraph.BVGraph' format.  
	2. To get webgraph running: I downloaded webgraph-<version>.jar from maven and the dependencies tarball from the above website, and added the jar to dependencies folder.
		And I run web-graph like so: java -cp .\webgraph-deps\* it.unimi.dsi.big.webgraph.BVGraph -o -O -L .\twitter-2010
	3. In this case, we convert the graphs downloaded from LAW website from BVGraph to ASCIIGraph format, that outputs .graph-txt file.
		java -cp .\webgraph-deps\* it.unimi.dsi.big.webgraph.Transform identity .\twitter\twitter-2010 twitter-out1 -d it.unimi.dsi.big.webgraph.ASCIIGraph
	4. Remove the first line (number of nodes) and prepend every line with the vertext number (i.e., line number - 1)
		tail -n +2 twitter.graph-txt > twitter.graph-txt1
		nl --starting-line-number=0 twitter.graph-txt1 > twitter.graph-txt 
		
	5. Copy this file over to hdfs (See example commands in step 2 above).
	6. On Giraph side, use the same parser as above. (org/apache/giraph/io/formats/LongDoubleFloatTextInputFormat.java)



========================================= OTHER SOFTWARE INSTALLED ON NODES =====================================================
	
1. Installed sysstat on all nodes to use `sar`
	sudo apt-get install sysstat

2. 
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
